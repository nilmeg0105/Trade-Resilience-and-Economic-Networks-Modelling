{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLTARspGYfkdITVPc48hhD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilmeg0105/Trade-Resilience-and-Economic-Networks-Modelling/blob/main/DPL_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ0qgtHqiZkw",
        "outputId": "624c27b9-d637-4938-80be-5ccf3d5db3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned DataFrame Shape: (525, 20)\n",
            "Missing Values:\n",
            " Series Code\n",
            "Country Name                        0\n",
            "Country Code                        0\n",
            "ISO                                 0\n",
            "Year                                0\n",
            "imports_goods_services_gdp_pct      0\n",
            "exports_goods_services_gdp_pct      0\n",
            "trade_gdp_pct                       0\n",
            "inflation_consumer_prices_pct      25\n",
            "gdp_growth_pct                      0\n",
            "gdp_per_capita_current_usd          0\n",
            "gdp_current_usd                     0\n",
            "trade_balance_gdp_pct               0\n",
            "gdp_growth_stability               21\n",
            "inflation_stability                45\n",
            "log_gdp_current_usd                 0\n",
            "log_gdp_per_capita                  0\n",
            "trade_vulnerability_index         525\n",
            "economic_shock_sensitivity         45\n",
            "per_capita_trade_intensity        525\n",
            "data_source                         0\n",
            "dtype: int64\n",
            "Summary Stats:\n",
            " Series Code        Year  imports_goods_services_gdp_pct  \\\n",
            "count         525.00000                      525.000000   \n",
            "mean         2012.00000                       31.819185   \n",
            "std             7.21798                       14.575148   \n",
            "min          2000.00000                        9.098877   \n",
            "25%          2006.00000                       21.824516   \n",
            "50%          2012.00000                       29.091260   \n",
            "75%          2018.00000                       38.466555   \n",
            "max          2024.00000                       96.699849   \n",
            "\n",
            "Series Code  exports_goods_services_gdp_pct  trade_gdp_pct  \\\n",
            "count                            525.000000     525.000000   \n",
            "mean                              30.933184      62.752369   \n",
            "std                               16.041025      29.252069   \n",
            "min                                8.221611      19.559604   \n",
            "25%                               19.335630      42.203732   \n",
            "50%                               28.927848      60.208122   \n",
            "75%                               38.730943      75.327818   \n",
            "max                               95.239596     191.939444   \n",
            "\n",
            "Series Code  inflation_consumer_prices_pct  gdp_growth_pct  \\\n",
            "count                           500.000000      525.000000   \n",
            "mean                              3.768691        3.041137   \n",
            "std                               5.441488        5.113220   \n",
            "min                             -10.067493      -36.656780   \n",
            "25%                               1.193017        1.067750   \n",
            "50%                               2.443188        2.745685   \n",
            "75%                               4.917284        5.401311   \n",
            "max                              53.230963       53.385547   \n",
            "\n",
            "Series Code  gdp_per_capita_current_usd  gdp_current_usd  \\\n",
            "count                        525.000000     5.250000e+02   \n",
            "mean                       23057.603140     1.467475e+12   \n",
            "std                        18910.218834     2.482725e+12   \n",
            "min                          138.706822     2.813572e+09   \n",
            "25%                         3342.636503     1.893821e+11   \n",
            "50%                        22267.721705     5.282075e+11   \n",
            "75%                        39065.424437     1.827638e+12   \n",
            "max                        68190.701004     1.874380e+13   \n",
            "\n",
            "Series Code  trade_balance_gdp_pct  gdp_growth_stability  inflation_stability  \\\n",
            "count                   525.000000            504.000000           480.000000   \n",
            "mean                     -0.886001              2.808495             1.882970   \n",
            "std                       9.155073              4.089679             3.413740   \n",
            "min                     -36.125385              0.036260             0.000000   \n",
            "25%                      -3.703002              0.779186             0.452075   \n",
            "50%                      -0.117698              1.538960             0.891966   \n",
            "75%                       2.864655              3.403787             2.002688   \n",
            "max                      32.147410             46.026142            32.870939   \n",
            "\n",
            "Series Code  log_gdp_current_usd  log_gdp_per_capita  \\\n",
            "count                 525.000000          525.000000   \n",
            "mean                   26.932392            9.301389   \n",
            "std                     1.672845            1.576566   \n",
            "min                    21.757721            4.939546   \n",
            "25%                    25.967033            8.114814   \n",
            "50%                    26.992755           10.010938   \n",
            "75%                    28.234045           10.573019   \n",
            "max                    30.561884           11.130078   \n",
            "\n",
            "Series Code  trade_vulnerability_index  economic_shock_sensitivity  \\\n",
            "count                              0.0                  480.000000   \n",
            "mean                               NaN                    1.613098   \n",
            "std                                NaN                    2.791364   \n",
            "min                                NaN                   -4.853456   \n",
            "25%                                NaN                    0.222636   \n",
            "50%                                NaN                    1.086948   \n",
            "75%                                NaN                    2.166202   \n",
            "max                                NaN                   19.734216   \n",
            "\n",
            "Series Code  per_capita_trade_intensity  \n",
            "count                               0.0  \n",
            "mean                                NaN  \n",
            "std                                 NaN  \n",
            "min                                 NaN  \n",
            "25%                                 NaN  \n",
            "50%                                 NaN  \n",
            "75%                                 NaN  \n",
            "max                                 NaN  \n",
            "Cleaned dataset saved to cleaned_core_economic_indicators.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "fp='Core_economic_indicators (1).csv'\n",
        "d=pd.read_csv(fp)\n",
        "\n",
        "# drop junk rows\n",
        "d=d.dropna(subset=['Country Name'])\n",
        "d=d[~d['Country Name'].str.contains('Data from database|Last Updated',na=False)]\n",
        "\n",
        "yrs=[c for c in d.columns if '[YR' in c]\n",
        "ymap={c:c.split()[0] for c in yrs}\n",
        "d.rename(columns=ymap,inplace=True)\n",
        "\n",
        "idv=['Country Name','Country Code','Series Name','Series Code']\n",
        "valv=[str(y) for y in range(2000,2025)]\n",
        "dl=pd.melt(d,id_vars=idv,value_vars=valv,var_name='Year',value_name='val')\n",
        "\n",
        "dl['val']=dl['val'].replace('..',np.nan)  # replace weird ..\n",
        "dl['val']=pd.to_numeric(dl['val'],errors='coerce')\n",
        "\n",
        "# pivot to wide\n",
        "dp=dl.pivot_table(index=['Country Name','Country Code','Year'],columns='Series Code',values='val').reset_index()\n",
        "\n",
        "cr={'NE.IMP.GNFS.ZS':'imports_goods_services_gdp_pct','NE.EXP.GNFS.ZS':'exports_goods_services_gdp_pct',\n",
        "'NE.TRD.GNFS.ZS':'trade_gdp_pct','FP.CPI.TOTL.ZG':'inflation_consumer_prices_pct','NY.GDP.MKTP.KD.ZG':'gdp_growth_pct',\n",
        "'NY.GDP.PCAP.CD':'gdp_per_capita_current_usd','NY.GDP.MKTP.CD':'gdp_current_usd'}\n",
        "dp.rename(columns=cr,inplace=True)\n",
        "\n",
        "dp['Year']=dp['Year'].astype(int)\n",
        "numc=list(cr.values())\n",
        "dp[numc]=dp[numc].astype(float)\n",
        "\n",
        "# focus only on some countries\n",
        "cc=['India','USA','Russia','France','Germany','Italy','China','Japan','Argentina','Portugal','Spain','Croatia','Belgium',\n",
        "'Australia','Pakistan','Afghanistan','Israel','Iran','Iraq','Bangladesh','Sri Lanka','Canada','UK','Sweden','Saudi Arabia']\n",
        "dp=dp[dp['Country Name'].isin(cc)]\n",
        "\n",
        "iso={'USA':'USA','RUS':'RUS','FRA':'FRA','DEU':'DEU','ITA':'ITA','CHN':'CHN','JPN':'JPN','ARG':'ARG','PRT':'PRT','ESP':'ESP',\n",
        "'HRV':'HRV','BEL':'BEL','AUS':'AUS','PAK':'PAK','AFG':'AFG','ISR':'ISR','IRN':'IRN','IRQ':'IRQ','BGD':'BGD','LKA':'LKA','CAN':'CAN','GBR':'GBR','SWE':'SWE','SAU':'SAU'}\n",
        "dp['ISO']=dp['Country Code'].map(iso).fillna(dp['Country Code'])\n",
        "\n",
        "dp.drop_duplicates(subset=['Country Name','Year'],inplace=True)\n",
        "dp['is_outlier']=((dp['gdp_growth_pct']>20)|(dp['gdp_growth_pct']<-20)).astype(int) # flag crazy values\n",
        "\n",
        "dp.sort_values(['Country Name','Year'],inplace=True)\n",
        "dp[numc]=dp.groupby('Country Name')[numc].transform(lambda x:x.interpolate(method='linear'))\n",
        "dp[numc]=dp.groupby('Country Name')[numc].transform(lambda x:x.fillna(x.mean()))  # still missing? use mean\n",
        "\n",
        "sl=['Country Name','Country Code','ISO','Year','imports_goods_services_gdp_pct','exports_goods_services_gdp_pct',\n",
        "'trade_gdp_pct','inflation_consumer_prices_pct','gdp_growth_pct','gdp_per_capita_current_usd','gdp_current_usd']\n",
        "dc=dp[sl].copy()\n",
        "\n",
        "dc['trade_balance_gdp_pct']=dc['exports_goods_services_gdp_pct']-dc['imports_goods_services_gdp_pct']\n",
        "dc['gdp_growth_stability']=dc.groupby('Country Name')['gdp_growth_pct'].transform(lambda x:x.rolling(window=3,min_periods=1).std())\n",
        "dc['inflation_stability']=dc.groupby('Country Name')['inflation_consumer_prices_pct'].transform(lambda x:x.rolling(window=3,min_periods=1).std())\n",
        "dc['log_gdp_current_usd']=np.log1p(dc['gdp_current_usd'])\n",
        "dc['log_gdp_per_capita']=np.log1p(dc['gdp_per_capita_current_usd'])\n",
        "\n",
        "# temp placeholders\n",
        "dc['trade_vulnerability_index']=np.nan\n",
        "dc['economic_shock_sensitivity']=0.4*dc['gdp_growth_stability']+0.4*dc['inflation_stability']+0.2*dc['trade_balance_gdp_pct']\n",
        "dc['per_capita_trade_intensity']=np.nan\n",
        "\n",
        "dc['data_source']='core_economic_indicators'\n",
        "\n",
        "print(\"shp:\",dc.shape)\n",
        "print(\"nulls:\\n\",dc.isnull().sum()) # quick check\n",
        "print(\"desc:\\n\",dc.describe())\n",
        "\n",
        "op='cleaned_core_economic_indicators.csv'\n",
        "dc.to_csv(op,index=False)\n",
        "print(\"saved:\",op)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path=\"crop_and_livestock (1).csv\"\n",
        "df=pd.read_csv(path)\n",
        "df.columns=df.columns.str.strip()\n",
        "\n",
        "cols=[\"Domain Code\",\"Domain\",\"Area Code (M49)\",\"Area\",\"Element Code\",\"Element\",\"Item Code (CPC)\",\"Item\",\n",
        "\"Year Code\",\"Year\",\"Unit\",\"Value\",\"Flag\",\"Flag Description\",\"Note\"]\n",
        "df=df[[c for c in cols if c in df.columns]].copy()\n",
        "\n",
        "df[\"Year\"]=pd.to_numeric(df[\"Year\"],errors=\"coerce\").astype(\"Int64\")\n",
        "df[\"Value\"]=pd.to_numeric(df[\"Value\"],errors=\"coerce\")\n",
        "\n",
        "focus=[\"India\",\"USA\",\"Russia\",\"France\",\"Germany\",\"Italy\",\"China\",\"Japan\",\n",
        "\"Argentina\",\"Portugal\",\"Spain\",\"Croatia\",\"Belgium\",\"Australia\",\"Pakistan\",\n",
        "\"Afghanistan\",\"Israel\",\"Iran\",\"Iraq\",\"Bangladesh\",\"Sri Lanka\",\"Canada\",\n",
        "\"UK\",\"Sweden\",\"Saudi Arabia\"]\n",
        "df=df[df[\"Area\"].isin(focus)]\n",
        "\n",
        "# area harvested (make sure in ha)\n",
        "a=df[df[\"Element\"]==\"Area harvested\"].copy()\n",
        "a[\"area_ha\"]=a[\"Value\"]\n",
        "a.loc[a[\"Unit\"].str.contains(\"1000\",case=False,na=False),\"area_ha\"]=a[\"Value\"]*1000\n",
        "areas=a[[\"Area\",\"Item\",\"Year\",\"area_ha\"]]\n",
        "\n",
        "# yields to kg/ha\n",
        "y=df[df[\"Element\"]==\"Yield\"].copy()\n",
        "y[\"yield_kg_ha\"]=np.nan\n",
        "u=y[\"Unit\"].str.lower()\n",
        "y.loc[u.str.contains(\"kg/ha\",na=False),\"yield_kg_ha\"]=y[\"Value\"]\n",
        "y.loc[u.str.contains(\"hg/ha\",na=False),\"yield_kg_ha\"]=y[\"Value\"]*0.1\n",
        "y.loc[u.str.contains(\"t/ha\",na=False)|u.str.contains(\"tonnes per hectare\",na=False),\"yield_kg_ha\"]=y[\"Value\"]*1000\n",
        "yields=y[[\"Area\",\"Item\",\"Year\",\"yield_kg_ha\"]]\n",
        "\n",
        "# production numbers directly\n",
        "p=df[df[\"Element\"]==\"Production\"].copy()\n",
        "p2=p[[\"Area\",\"Item\",\"Year\",\"Value\"]].rename(columns={\"Value\":\"reported_production_tonnes\"})\n",
        "\n",
        "# estimate prod by yield*area\n",
        "base=pd.merge(yields,areas,on=[\"Area\",\"Item\",\"Year\"],how=\"outer\")\n",
        "base[\"yield_kg_ha\"]=base.groupby([\"Area\",\"Item\"])[\"yield_kg_ha\"].transform(lambda x:x.interpolate(method=\"linear\"))\n",
        "base[\"area_ha\"]=base.groupby([\"Area\",\"Item\"])[\"area_ha\"].transform(lambda x:x.interpolate(method=\"linear\"))\n",
        "base[\"estimated_production_tonnes\"]=(base[\"yield_kg_ha\"]*base[\"area_ha\"])/1000\n",
        "prod=base[[\"Area\",\"Item\",\"Year\",\"estimated_production_tonnes\",\"yield_kg_ha\",\"area_ha\"]]\n",
        "\n",
        "if not prod.empty:\n",
        "    prod[\"_w\"]=prod[\"area_ha\"].fillna(0)\n",
        "    prod[\"_y_w\"]=prod[\"yield_kg_ha\"].fillna(0)*prod[\"_w\"]\n",
        "    w=prod.groupby([\"Area\",\"Year\"],as_index=False).agg(\n",
        "        total_area_harvested_ha=(\"area_ha\",\"sum\"),\n",
        "        est_ag_production_tonnes=(\"estimated_production_tonnes\",\"sum\"),\n",
        "        _y_w_sum=(\"_y_w\",\"sum\"),\n",
        "        _w_sum=(\"_w\",\"sum\")\n",
        "    )\n",
        "    w[\"avg_crop_yield_kg_ha\"]=np.where(w[\"_w_sum\"]>0,w[\"_y_w_sum\"]/w[\"_w_sum\"],np.nan)\n",
        "    w=w.drop(columns=[\"_y_w_sum\",\"_w_sum\"])\n",
        "else:\n",
        "    w=pd.DataFrame(columns=[\"Area\",\"Year\",\"total_area_harvested_ha\",\"est_ag_production_tonnes\",\"avg_crop_yield_kg_ha\"])\n",
        "\n",
        "agg=pd.merge(w,p2.groupby([\"Area\",\"Year\"],as_index=False).agg(\n",
        "    reported_production_tonnes=(\"reported_production_tonnes\",\"sum\")\n",
        "),on=[\"Area\",\"Year\"],how=\"outer\")\n",
        "\n",
        "agg=agg.rename(columns={\"Area\":\"Country\"})\n",
        "agg=agg.sort_values([\"Country\",\"Year\"]).reset_index(drop=True)\n",
        "\n",
        "for c in [\"total_area_harvested_ha\",\"est_ag_production_tonnes\",\"reported_production_tonnes\"]:\n",
        "    if c in agg.columns: agg[c]=agg[c].fillna(0)\n",
        "\n",
        "# extra indicators\n",
        "yagg=yields.groupby([\"Area\",\"Year\"]).agg(yield_kg_ha=(\"yield_kg_ha\",\"mean\")).reset_index()\n",
        "yagg=yagg.rename(columns={\"Area\":\"Country\"})\n",
        "agg=pd.merge(agg,yagg,on=[\"Country\",\"Year\"],how=\"left\")\n",
        "\n",
        "agg[\"is_yield_outlier\"]=(agg[\"yield_kg_ha\"]>10000).astype(int)\n",
        "agg[\"production_discrepancy_flag\"]=np.where(\n",
        "    (agg[\"est_ag_production_tonnes\"]>0)&(agg[\"reported_production_tonnes\"]>0)&\n",
        "    (abs(agg[\"est_ag_production_tonnes\"]-agg[\"reported_production_tonnes\"])/agg[\"reported_production_tonnes\"]>0.1),1,0\n",
        ")\n",
        "\n",
        "agg[\"food_production_index\"]=np.where(\n",
        "    agg[\"total_area_harvested_ha\"]>0,\n",
        "    agg[\"avg_crop_yield_kg_ha\"]*agg[\"total_area_harvested_ha\"]/1000,\n",
        "    np.nan\n",
        ")\n",
        "\n",
        "agg[\"yield_variability\"]=agg.groupby(\"Country\")[\"yield_kg_ha\"].transform(lambda x:x.rolling(window=3,min_periods=1).std())\n",
        "\n",
        "# crop diversity\n",
        "div=prod.groupby([\"Area\",\"Year\"]).agg(crop_diversity_index=(\"Item\",\"nunique\")).reset_index()\n",
        "div=div.rename(columns={\"Area\":\"Country\"})\n",
        "agg=pd.merge(agg,div,on=[\"Country\",\"Year\"],how=\"left\")\n",
        "\n",
        "agg[\"agricultural_export_potential\"]=np.nan\n",
        "\n",
        "out=\"crop_livestock_processed.csv\"\n",
        "agg.to_csv(out,index=False)\n",
        "print(\"Saved:\",out)\n",
        "print(agg.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrSiamkkkNVZ",
        "outputId": "3c19fccc-aaf7-4e82-d4c6-a5fa9f25e2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: crop_livestock_processed.csv\n",
            "       Country  Year  total_area_harvested_ha  est_ag_production_tonnes  \\\n",
            "0  Afghanistan  2000                2800315.0              4.355680e+06   \n",
            "1  Afghanistan  2001                2484514.0              4.547215e+06   \n",
            "2  Afghanistan  2002                2627078.0              6.179899e+06   \n",
            "3  Afghanistan  2003                3390751.0              6.981472e+06   \n",
            "4  Afghanistan  2004                3036039.0              5.954611e+06   \n",
            "5  Afghanistan  2005                3471747.0              8.125423e+06   \n",
            "6  Afghanistan  2006                3418127.0              7.447336e+06   \n",
            "7  Afghanistan  2007                3463717.0              8.666459e+06   \n",
            "8  Afghanistan  2008                3152361.0              6.751566e+06   \n",
            "9  Afghanistan  2009                3649144.0              9.641292e+06   \n",
            "\n",
            "   avg_crop_yield_kg_ha  reported_production_tonnes  yield_kg_ha  \\\n",
            "0           1555.424956                  7406816.82  5751.545714   \n",
            "1           1830.223302                  6744376.45  5853.485714   \n",
            "2           2352.384976                  9547127.03  5881.768571   \n",
            "3           2058.975039                 10128963.20  5809.580000   \n",
            "4           1961.309285                  9223923.31  5979.080000   \n",
            "5           2340.442180                 11412745.12  5779.691429   \n",
            "6           2178.776882                 10392699.20  5715.880000   \n",
            "7           2502.068913                 11797813.27  5868.705714   \n",
            "8           2141.749113                  9853121.80  6053.042857   \n",
            "9           2642.069378                 12802617.60  7209.711429   \n",
            "\n",
            "   is_yield_outlier  production_discrepancy_flag  food_production_index  \\\n",
            "0                 0                            1           4.355680e+06   \n",
            "1                 0                            1           4.547215e+06   \n",
            "2                 0                            1           6.179899e+06   \n",
            "3                 0                            1           6.981472e+06   \n",
            "4                 0                            1           5.954611e+06   \n",
            "5                 0                            1           8.125423e+06   \n",
            "6                 0                            1           7.447336e+06   \n",
            "7                 0                            1           8.666459e+06   \n",
            "8                 0                            1           6.751566e+06   \n",
            "9                 0                            1           9.641292e+06   \n",
            "\n",
            "   yield_variability  crop_diversity_index  agricultural_export_potential  \n",
            "0                NaN                    36                            NaN  \n",
            "1          72.082465                    36                            NaN  \n",
            "2          68.495348                    36                            NaN  \n",
            "3          36.374949                    36                            NaN  \n",
            "4          85.059738                    36                            NaN  \n",
            "5         107.532460                    36                            NaN  \n",
            "6         137.296480                    36                            NaN  \n",
            "7          76.758431                    36                            NaN  \n",
            "8         168.826673                    36                            NaN  \n",
            "9         726.883610                    36                            NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "\n",
        "d=pd.read_csv(\"Resiliance.csv\")   # load raw data\n",
        "\n",
        "d=d.replace(\"..\",np.nan)  # handle weird missing vals\n",
        "\n",
        "# reshape wide yrs into long tidy format\n",
        "dl=d.melt(id_vars=[\"Country Name\",\"Country Code\",\"Series Name\",\"Series Code\"],\n",
        "var_name=\"Year\",value_name=\"Val\")\n",
        "\n",
        "dl[\"Year\"]=dl[\"Year\"].str.extract(r\"(\\d{4})\").astype(int)  # clean year col\n",
        "dl[\"Val\"]=pd.to_numeric(dl[\"Val\"],errors=\"coerce\")  # convert vals\n",
        "\n",
        "dl=dl.sort_values([\"Country Name\",\"Series Name\",\"Year\"])  # keep in order\n",
        "dl[\"miss\"]=dl[\"Val\"].isna()  # mark which ones were missing\n",
        "\n",
        "# fill: interpolate tiny gaps, then forward/back fill edges\n",
        "def fillf(s): return s.interpolate(\"linear\",limit=1).ffill().bfill()\n",
        "\n",
        "dl[\"Val\"]=dl.groupby([\"Country Name\",\"Series Name\"])[\"Val\"].transform(fillf)\n",
        "dl[\"miss\"]=dl[\"miss\"] & dl[\"Val\"].notna()  # update imputed flag\n",
        "\n",
        "dl=dl.reset_index(drop=True)\n",
        "dl.to_csv(\"processed_timeseries_clean.csv\",index=False)  # save cleaned data\n",
        "\n",
        "print(dl.head(20))\n"
      ],
      "metadata": {
        "id": "e9ZmNVHjuK3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c7955d-7ec9-4cd4-c578-ed4e2f240694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Country Name Country Code                         Series Name  \\\n",
            "0   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "1   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "2   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "3   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "4   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "5   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "6   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "7   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "8   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "9   Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "10  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "11  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "12  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "13  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "14  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "15  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "16  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "17  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "18  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "19  Afghanistan          AFG  Current account balance (% of GDP)   \n",
            "\n",
            "          Series Code  Year      Value  Imputed  \n",
            "0   BN.CAB.XOKA.GD.ZS  2000  -2.357990     True  \n",
            "1   BN.CAB.XOKA.GD.ZS  2001  -2.357990     True  \n",
            "2   BN.CAB.XOKA.GD.ZS  2002  -2.357990     True  \n",
            "3   BN.CAB.XOKA.GD.ZS  2003  -2.357990     True  \n",
            "4   BN.CAB.XOKA.GD.ZS  2004  -2.357990     True  \n",
            "5   BN.CAB.XOKA.GD.ZS  2005  -2.357990     True  \n",
            "6   BN.CAB.XOKA.GD.ZS  2006  -2.357990     True  \n",
            "7   BN.CAB.XOKA.GD.ZS  2007  -2.357990     True  \n",
            "8   BN.CAB.XOKA.GD.ZS  2008  -2.357990    False  \n",
            "9   BN.CAB.XOKA.GD.ZS  2009   2.236019    False  \n",
            "10  BN.CAB.XOKA.GD.ZS  2010  -3.643314    False  \n",
            "11  BN.CAB.XOKA.GD.ZS  2011 -12.619538    False  \n",
            "12  BN.CAB.XOKA.GD.ZS  2012 -25.870681    False  \n",
            "13  BN.CAB.XOKA.GD.ZS  2013 -25.290059    False  \n",
            "14  BN.CAB.XOKA.GD.ZS  2014 -15.772420    False  \n",
            "15  BN.CAB.XOKA.GD.ZS  2015 -21.912657    False  \n",
            "16  BN.CAB.XOKA.GD.ZS  2016 -14.950195    False  \n",
            "17  BN.CAB.XOKA.GD.ZS  2017 -18.955961    False  \n",
            "18  BN.CAB.XOKA.GD.ZS  2018 -21.585274    False  \n",
            "19  BN.CAB.XOKA.GD.ZS  2019 -20.170464    False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "\n",
        "d=pd.read_csv(\"Employment_Unemployment.csv\")  # load data\n",
        "\n",
        "d=d.replace(\"..\",np.nan)  # fix missing vals\n",
        "\n",
        "# reshape wide yrs to long\n",
        "dl=d.melt(id_vars=[\"Country Name\",\"Country Code\",\"Series Name\",\"Series Code\"],\n",
        "var_name=\"Year\",value_name=\"Val\")\n",
        "\n",
        "dl[\"Year\"]=dl[\"Year\"].str.extract(r\"(\\d{4})\").astype(int)  # keep only year num\n",
        "dl[\"Val\"]=pd.to_numeric(dl[\"Val\"],errors=\"coerce\")  # force numeric\n",
        "\n",
        "dl=dl.sort_values([\"Country Name\",\"Series Name\",\"Year\"])  # order data\n",
        "dl[\"miss\"]=dl[\"Val\"].isna()  # mark na\n",
        "\n",
        "# fill small gaps only (linear, max 1 step)\n",
        "def fillf(s): return s.interpolate(\"linear\",limit=1)\n",
        "\n",
        "dl[\"Val\"]=dl.groupby([\"Country Name\",\"Series Name\"])[\"Val\"].transform(fillf)\n",
        "dl[\"miss\"]=dl[\"miss\"] & dl[\"Val\"].notna()  # update imputed flag\n",
        "\n",
        "dl=dl.reset_index(drop=True)\n",
        "dl.to_csv(\"processed_employment_unemployment.csv\",index=False)  # save\n",
        "\n",
        "print(dl.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGV051joxy4c",
        "outputId": "83efa107-cf72-416b-dbf6-354a1609a2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Country Name Country Code  \\\n",
            "0   Afghanistan          AFG   \n",
            "1   Afghanistan          AFG   \n",
            "2   Afghanistan          AFG   \n",
            "3   Afghanistan          AFG   \n",
            "4   Afghanistan          AFG   \n",
            "5   Afghanistan          AFG   \n",
            "6   Afghanistan          AFG   \n",
            "7   Afghanistan          AFG   \n",
            "8   Afghanistan          AFG   \n",
            "9   Afghanistan          AFG   \n",
            "10  Afghanistan          AFG   \n",
            "11  Afghanistan          AFG   \n",
            "12  Afghanistan          AFG   \n",
            "13  Afghanistan          AFG   \n",
            "14  Afghanistan          AFG   \n",
            "15  Afghanistan          AFG   \n",
            "16  Afghanistan          AFG   \n",
            "17  Afghanistan          AFG   \n",
            "18  Afghanistan          AFG   \n",
            "19  Afghanistan          AFG   \n",
            "\n",
            "                                          Series Name           Series Code  \\\n",
            "0   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "1   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "2   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "3   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "4   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "5   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "6   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "7   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "8   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "9   Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "10  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "11  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "12  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "13  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "14  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "15  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "16  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "17  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "18  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "19  Employment to population ratio, 15+, female (%...  SL.EMP.TOTL.SP.FE.ZS   \n",
            "\n",
            "    Year   Value  Imputed  \n",
            "0   2000  12.820    False  \n",
            "1   2001  12.728    False  \n",
            "2   2002  12.691    False  \n",
            "3   2003  12.700    False  \n",
            "4   2004  12.741    False  \n",
            "5   2005  12.830    False  \n",
            "6   2006  12.958    False  \n",
            "7   2007  13.168    False  \n",
            "8   2008  13.402    False  \n",
            "9   2009  13.694    False  \n",
            "10  2010  13.983    False  \n",
            "11  2011  14.265    False  \n",
            "12  2012  14.534    False  \n",
            "13  2013  15.361    False  \n",
            "14  2014  16.239    False  \n",
            "15  2015  16.893    False  \n",
            "16  2016  17.569    False  \n",
            "17  2017  18.262    False  \n",
            "18  2018  16.879    False  \n",
            "19  2019  15.458    False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def process_social_welfare(input_csv: str, output_csv: str) -> pd.DataFrame:\n",
        "    # --- Load & normalize ---\n",
        "    df = pd.read_csv(input_csv)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    df = df.replace(\"..\", np.nan)\n",
        "\n",
        "    id_vars = [c for c in [\"Country Name\", \"Country Code\", \"Series Name\", \"Series Code\"] if c in df.columns]\n",
        "    value_vars = [c for c in df.columns if c not in id_vars]\n",
        "\n",
        "    # --- Wide -> Long (Unpivot) ---\n",
        "    long = df.melt(id_vars=id_vars, value_vars=value_vars,\n",
        "                   var_name=\"Year\", value_name=\"Value\")\n",
        "\n",
        "    long[\"Year\"]  = long[\"Year\"].astype(str).str.extract(r\"(\\d{4})\").astype(int)\n",
        "    long[\"Value\"] = pd.to_numeric(long[\"Value\"], errors=\"coerce\")\n",
        "\n",
        "    long = long.sort_values([\"Country Name\",\"Country Code\",\"Series Code\",\"Year\"]).reset_index(drop=True)\n",
        "    long[\"Imputed\"] = False\n",
        "    long[\"Impute_Method\"] = \"original\"\n",
        "\n",
        "    # --- Indicator-aware rules ---\n",
        "    def rules_for(series_code: str):\n",
        "        code = str(series_code)\n",
        "        if code.startswith(\"SP.DYN.LE00\"):          # Life expectancy (very smooth)\n",
        "            return dict(limit=3, fill_edges=True)\n",
        "        if code == \"SP.URB.TOTL.IN.ZS\":            # Urban population % (smooth)\n",
        "            return dict(limit=2, fill_edges=True)\n",
        "        if code == \"SP.POP.GROW\":                  # Pop growth % (rate)\n",
        "            return dict(limit=1, fill_edges=False)\n",
        "        if code == \"SL.UEM.TOTL.ZS\":               # Unemployment % (gradual)\n",
        "            return dict(limit=1, fill_edges=False)\n",
        "        if code == \"SI.POV.GINI\":                  # Gini (survey, irregular)\n",
        "            return dict(limit=0, fill_edges=False)\n",
        "        if code == \"SI.POV.DDAY\":                  # Poverty headcount (survey)\n",
        "            return dict(limit=0, fill_edges=False)\n",
        "        # Default conservative rule\n",
        "        return dict(limit=1, fill_edges=False)\n",
        "\n",
        "    # --- Apply per (country, series) group ---\n",
        "    out = []\n",
        "    grp_cols = [\"Country Name\",\"Country Code\",\"Series Code\",\"Series Name\"]\n",
        "    for keys, g in long.groupby(grp_cols, sort=False):\n",
        "        rule = rules_for(g[\"Series Code\"].iloc[0])\n",
        "        s = g[\"Value\"].copy()\n",
        "        method = pd.Series(\"original\", index=g.index)\n",
        "\n",
        "        # Interpolate only up to `limit` consecutive missing years (internal gaps)\n",
        "        if rule[\"limit\"] > 0:\n",
        "            s_interp = s.interpolate(method=\"linear\", limit=rule[\"limit\"])\n",
        "            method.loc[s.isna() & s_interp.notna()] = \"interp\"\n",
        "        else:\n",
        "            s_interp = s\n",
        "\n",
        "        # Optionally fill edges (start/end) with last/next observation\n",
        "        if rule[\"fill_edges\"]:\n",
        "            s_ff = s_interp.ffill()\n",
        "            method.loc[s_interp.isna() & s_ff.notna()] = \"ffill\"\n",
        "            s_fb = s_ff.bfill()\n",
        "            method.loc[s_ff.isna() & s_fb.notna()] = \"bfill\"\n",
        "            s_final = s_fb\n",
        "        else:\n",
        "            s_final = s_interp\n",
        "\n",
        "        g = g.copy()\n",
        "        g[\"Value\"] = s_final\n",
        "        g[\"Imputed\"] = method.ne(\"original\")\n",
        "        g[\"Impute_Method\"] = method\n",
        "        out.append(g)\n",
        "\n",
        "    final = pd.concat(out, axis=0).sort_values(\n",
        "        [\"Country Name\",\"Country Code\",\"Series Code\",\"Year\"]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    final.to_csv(output_csv, index=False)\n",
        "    return final\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Change the paths as needed\n",
        "    processed = process_social_welfare(\n",
        "        \"Social_and_welfare.csv\",\n",
        "        \"processed_social_and_welfare.csv\"\n",
        "    )\n",
        "    print(processed.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBtHjwN_zYa0",
        "outputId": "721a4bc9-7d84-470b-cff5-2d9c08ccb5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Country Name Country Code  \\\n",
            "0   Afghanistan          AFG   \n",
            "1   Afghanistan          AFG   \n",
            "2   Afghanistan          AFG   \n",
            "3   Afghanistan          AFG   \n",
            "4   Afghanistan          AFG   \n",
            "5   Afghanistan          AFG   \n",
            "6   Afghanistan          AFG   \n",
            "7   Afghanistan          AFG   \n",
            "8   Afghanistan          AFG   \n",
            "9   Afghanistan          AFG   \n",
            "10  Afghanistan          AFG   \n",
            "11  Afghanistan          AFG   \n",
            "12  Afghanistan          AFG   \n",
            "13  Afghanistan          AFG   \n",
            "14  Afghanistan          AFG   \n",
            "15  Afghanistan          AFG   \n",
            "16  Afghanistan          AFG   \n",
            "17  Afghanistan          AFG   \n",
            "18  Afghanistan          AFG   \n",
            "19  Afghanistan          AFG   \n",
            "\n",
            "                                          Series Name  Series Code  Year  \\\n",
            "0   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2000   \n",
            "1   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2001   \n",
            "2   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2002   \n",
            "3   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2003   \n",
            "4   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2004   \n",
            "5   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2005   \n",
            "6   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2006   \n",
            "7   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2007   \n",
            "8   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2008   \n",
            "9   Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2009   \n",
            "10  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2010   \n",
            "11  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2011   \n",
            "12  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2012   \n",
            "13  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2013   \n",
            "14  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2014   \n",
            "15  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2015   \n",
            "16  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2016   \n",
            "17  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2017   \n",
            "18  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2018   \n",
            "19  Poverty headcount ratio at $3.00 a day (2021 P...  SI.POV.DDAY  2019   \n",
            "\n",
            "    Value  Imputed Impute_Method  \n",
            "0     NaN    False      original  \n",
            "1     NaN    False      original  \n",
            "2     NaN    False      original  \n",
            "3     NaN    False      original  \n",
            "4     NaN    False      original  \n",
            "5     NaN    False      original  \n",
            "6     NaN    False      original  \n",
            "7     NaN    False      original  \n",
            "8     NaN    False      original  \n",
            "9     NaN    False      original  \n",
            "10    NaN    False      original  \n",
            "11    NaN    False      original  \n",
            "12    NaN    False      original  \n",
            "13    NaN    False      original  \n",
            "14    NaN    False      original  \n",
            "15    NaN    False      original  \n",
            "16    NaN    False      original  \n",
            "17    NaN    False      original  \n",
            "18    NaN    False      original  \n",
            "19    NaN    False      original  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# just keep 25 countries we care abt\n",
        "cts=[\"India\",\"USA\",\"Russia\",\"France\",\"Germany\",\"Italy\",\"China\",\"Japan\",\"Argentina\",\"Portugal\",\n",
        "     \"Spain\",\"Croatia\",\"Belgium\",\"Australia\",\"Pakistan\",\"Afghanistan\",\"Israel\",\"Iran\",\"Iraq\",\n",
        "     \"Bangladesh\",\"Sri Lanka\",\"Canada\",\"UK\",\"Sweden\",\"Saudi Arabia\"]\n",
        "\n",
        "df=pd.read_csv(\"export_processed.csv\",encoding=\"latin1\")\n",
        "df=df[df[\"reporterDesc\"].isin(cts)]   # filter only chosen\n",
        "\n",
        "df.to_csv(\"export_processed.csv\",index=False)\n",
        "print(\"export_processed.csv updated with 25 countries only\")\n",
        "\n",
        "# find per-year max TDI (kinda like worst case dep)\n",
        "mx=df.groupby([\"reporterDesc\",\"refYear\"])[\"TradeDependencyIndex\"].max().reset_index()\n",
        "\n",
        "# avg of those yearly max per country\n",
        "avg=mx.groupby(\"reporterDesc\")[\"TradeDependencyIndex\"].mean().reset_index()\n",
        "top3=avg.sort_values(\"TradeDependencyIndex\",ascending=False).head(3)\n",
        "\n",
        "print(\"\\nTop 3 Vulnerable Nations by Avg Max TDI:\")\n",
        "print(top3[[\"reporterDesc\",\"TradeDependencyIndex\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDXPgjbjDL5",
        "outputId": "60e772c3-cd6c-4faa-ed87-6556b130e10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export_processed.csv has been updated with only the specified 25 countries.\n",
            "\n",
            "Top 3 Vulnerable Nations by Average Max Trade Dependency Index:\n",
            "   reporterDesc  TradeDependencyIndex\n",
            "5        Canada              0.861269\n",
            "12         Iraq              0.757560\n",
            "0   Afghanistan              0.497160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Prophet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkVgL566ouen",
        "outputId": "8356f734-ea65-4d9b-8864-80d4a00f9a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Prophet in /usr/local/lib/python3.11/dist-packages (1.1.7)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from Prophet) (1.2.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from Prophet) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from Prophet) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from Prophet) (2.2.2)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.11/dist-packages (from Prophet) (0.78)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from Prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from Prophet) (6.5.2)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy>=1.0.4->Prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays<1,>=0.25->Prophet) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->Prophet) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->Prophet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.4->Prophet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays<1,>=0.25->Prophet) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kJhyf7JRBE9",
        "outputId": "a26d1917-cb67-4052-de4c-2229e9e93152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np, tensorflow as tf, optuna\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# load data\n",
        "exp=pd.read_csv(\"export_processed.csv\",encoding=\"latin1\");integ=pd.read_csv(\"integrated_master.csv\",encoding=\"latin1\")\n",
        "ctrys=[\"India\",\"USA\",\"Russia\",\"France\",\"Germany\",\"Italy\",\"China\",\"Japan\",\"Argentina\",\"Portugal\",\"Spain\",\"Croatia\",\"Belgium\",\"Australia\",\"Pakistan\",\"Afghanistan\",\"Israel\",\"Iran\",\"Iraq\",\"Bangladesh\",\"Sri Lanka\",\"Canada\",\"UK\",\"Sweden\",\"Saudi Arabia\"]\n",
        "exp=exp[exp[\"reporterDesc\"].isin(ctrys)]\n",
        "\n",
        "# find vuln\n",
        "mx=exp.groupby([\"reporterDesc\",\"refYear\"])[\"TradeDependencyIndex\"].max().reset_index()\n",
        "av=mx.groupby(\"reporterDesc\")[\"TradeDependencyIndex\"].mean().reset_index()\n",
        "t3=av.sort_values(by=\"TradeDependencyIndex\",ascending=False).head(3)\n",
        "print(\"\\nTop 3 vulnerable (by avg yearly max TDI):\");print(t3)\n",
        "\n",
        "# find top partners per country\n",
        "tp=[]\n",
        "for c in t3[\"reporterDesc\"]:\n",
        "    s=exp[exp[\"reporterDesc\"]==c];yr=s[\"refYear\"].max();sl=s[s[\"refYear\"]==yr]\n",
        "    p=sl.sort_values(\"TradeDependencyIndex\",ascending=False).iloc[0]\n",
        "    tp.append({\"country\":c,\"partner\":p[\"partnerDesc\"],\"partner_export_share\":p[\"TradeDependencyIndex\"],\"year_basis\":yr})\n",
        "tpd=pd.DataFrame(tp)\n",
        "print(\"\\nTop partner & export share (latest year):\");print(tpd)\n",
        "\n",
        "# helper for sequence making\n",
        "def mkseq(X,y,w=3):\n",
        "    xx,yy=[],[]\n",
        "    for i in range(len(X)-w): xx.append(X[i:i+w]);yy.append(y[i+w])\n",
        "    return np.array(xx),np.array(yy)\n",
        "\n",
        "# optuna obj (bad naming, minimal doc)\n",
        "def obj(tr,Xtr,ytr,Xv,yv,inp):\n",
        "    u=tr.suggest_int(\"units\",32,128);l=tr.suggest_int(\"layers\",1,3);d=tr.suggest_float(\"dropout\",0.1,0.5);lr=tr.suggest_loguniform(\"lr\",1e-4,1e-2)\n",
        "    m=keras.Sequential()\n",
        "    for i in range(l):\n",
        "        rs=(i<l-1)\n",
        "        m.add(layers.LSTM(u,activation=\"tanh\",return_sequences=rs,input_shape=inp if i==0 else None))\n",
        "        m.add(layers.Dropout(d))\n",
        "    m.add(layers.Dense(1))\n",
        "    m.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),loss=\"mse\")\n",
        "    es=keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,restore_best_weights=True)\n",
        "    h=m.fit(Xtr,ytr,validation_data=(Xv,yv),epochs=100,batch_size=tr.suggest_categorical(\"batch_size\",[8,16,32]),verbose=0,callbacks=[es])\n",
        "    return min(h.history[\"val_loss\"])\n",
        "\n",
        "# run model per country\n",
        "smry=[]\n",
        "feats=[\"imports_goods_services_gdp_pct\",\"exports_goods_services_gdp_pct\",\"trade_gdp_pct\",\"inflation_consumer_prices_pct\",\"gdp_growth_pct\",\"trade_balance_gdp_pct\",\"gdp_growth_stability\",\"inflation_stability\",\"HHI_export\",\"Diversification_export\",\"HHI_import\",\"Diversification_import\",\"Trade_Diversification_Index\",\"Overall_Trade_Dependency\"]\n",
        "tgt=\"gdp_current_usd\"\n",
        "for _,r in tpd.iterrows():\n",
        "    c=r[\"country\"];p=r[\"partner\"];shr=r[\"partner_export_share\"]\n",
        "    print(f\"\\n==============================\");print(f\"Country: {c} | Top partner: {p} ({shr:.2f})\");print(\"==============================\")\n",
        "    df=integ[integ[\"Country Name\"]==c].copy();df=df.dropna(subset=feats+[tgt])\n",
        "    if df.empty or df[\"Year\"].nunique()<10: print(f\"Not enough data for {c}. Skipping.\");continue\n",
        "    sx=MinMaxScaler();sy=MinMaxScaler();X=sx.fit_transform(df[feats]);y=sy.fit_transform(df[[tgt]])\n",
        "    Xs,ys=mkseq(X,y,3)\n",
        "\n",
        "    if len(Xs)<10:\n",
        "        print(f\"Too short sequence for {c}. Skipping.\");\n",
        "        continue\n",
        "    yrs=df[\"Year\"].values[3:]\n",
        "    trcut=np.where(yrs<=2022)[0][-1]\n",
        "    vcut=np.where(yrs<=2024)[0][-1]\n",
        "    Xtr,Ytr=Xs[:trcut+1],ys[:trcut+1]\n",
        "    Xv,Yv=Xs[trcut+1:vcut+1],ys[trcut+1:vcut+1]\n",
        "    Xt,Yt=Xs[vcut+1:],ys[vcut+1:]\n",
        "\n",
        "    st=optuna.create_study(direction=\"minimize\");st.optimize(lambda tr: obj(tr,Xtr,Ytr,Xv,Yv,(Xtr.shape[1],Xtr.shape[2])),n_trials=20,timeout=300)\n",
        "    bp=st.best_params\n",
        "    print(\"Best params:\",bp)\n",
        "    bm=keras.Sequential()\n",
        "\n",
        "    for i in range(bp[\"layers\"]):\n",
        "        rs=(i<bp[\"layers\"]-1)\n",
        "        bm.add(layers.LSTM(bp[\"units\"],activation=\"tanh\",return_sequences=rs,input_shape=(Xtr.shape[1],Xtr.shape[2]) if i==0 else None))\n",
        "        bm.add(layers.Dropout(bp[\"dropout\"]))\n",
        "    bm.add(layers.Dense(1));bm.compile(optimizer=keras.optimizers.Adam(learning_rate=bp[\"lr\"]),loss=\"mse\")\n",
        "    es=keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,restore_best_weights=True)\n",
        "    bm.fit(np.concatenate([Xtr,Xv]),np.concatenate([Ytr,Yv]),epochs=200,batch_size=bp[\"batch_size\"],verbose=0,callbacks=[es])\n",
        "    ls=Xs[-1:];bl=bm.predict(ls,verbose=0)[0][0];blv=sy.inverse_transform([[bl]])[0,0]\n",
        "    sh=ls.copy();idx=feats.index(\"Overall_Trade_Dependency\");sh[0,-1,idx]*=(1-0.40*shr)\n",
        "    shv=bm.predict(sh,verbose=0)[0][0];shv=sy.inverse_transform([[shv]])[0,0]\n",
        "    loss=blv-shv;lp=loss/blv*100\n",
        "    smry.append({\"country\":c,\"top_partner\":p,\"baseline_gdp_2026\":blv,\"shock_gdp_2026\":shv,\"gdp_loss\":loss,\"gdp_loss_pct\":lp})\n",
        "\n",
        "# print results\n",
        "if smry:\n",
        "    sm=pd.DataFrame(smry).sort_values(\"gdp_loss_pct\",ascending=False)\n",
        "    pd.set_option(\"display.float_format\",lambda v:f\"{v:,.2f}\")\n",
        "    print(\"\\n===== GDP Impact Summary (2026, 40% drop in top partner's imports, Tuned LSTM) =====\");print(sm)\n",
        "else: print(\"\\n No valid countries had enough data for tuned LSTM modeling.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBE-HEzKl2hE",
        "outputId": "33de9063-6f9d-43bb-c06a-a4cd0049383f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-19 12:18:36,989] A new study created in memory with name: no-name-feb3b7a7-aa97-46f4-b064-a854d4afd7ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 3 vulnerable (by avg yearly max TDI):\n",
            "   reporterDesc  TradeDependencyIndex\n",
            "5        Canada                  0.86\n",
            "12         Iraq                  0.76\n",
            "0   Afghanistan                  0.50\n",
            "\n",
            "Top partner & export share (latest year):\n",
            "       country partner  partner_export_share  year_basis\n",
            "0       Canada     USA                  0.85        2024\n",
            "1         Iraq   Italy                  0.88        2016\n",
            "2  Afghanistan   India                  0.51        2019\n",
            "\n",
            "==============================\n",
            "Country: Canada | Top partner: USA (0.85)\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-19 12:18:56,207] Trial 0 finished with value: 0.006466730032116175 and parameters: {'units': 81, 'layers': 3, 'dropout': 0.24039347666068003, 'lr': 0.0016048261989244424, 'batch_size': 8}. Best is trial 0 with value: 0.006466730032116175.\n",
            "[I 2025-08-19 12:19:12,225] Trial 1 finished with value: 0.01800517365336418 and parameters: {'units': 113, 'layers': 3, 'dropout': 0.4029050399022176, 'lr': 0.0001998041694267846, 'batch_size': 8}. Best is trial 0 with value: 0.006466730032116175.\n",
            "[I 2025-08-19 12:19:19,190] Trial 2 finished with value: 0.0003266715502832085 and parameters: {'units': 99, 'layers': 2, 'dropout': 0.32678593908266795, 'lr': 0.0011997020628456317, 'batch_size': 32}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:19:27,964] Trial 3 finished with value: 0.018452726304531097 and parameters: {'units': 66, 'layers': 2, 'dropout': 0.3932050904633957, 'lr': 0.00036921908727854556, 'batch_size': 16}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:19:37,873] Trial 4 finished with value: 0.003893975866958499 and parameters: {'units': 95, 'layers': 3, 'dropout': 0.28358798347430014, 'lr': 0.0007471239820944852, 'batch_size': 32}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:19:47,246] Trial 5 finished with value: 0.005163278430700302 and parameters: {'units': 48, 'layers': 3, 'dropout': 0.47726468620597895, 'lr': 0.004288918476720701, 'batch_size': 16}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:19:52,811] Trial 6 finished with value: 0.005157282575964928 and parameters: {'units': 65, 'layers': 2, 'dropout': 0.1448857932650503, 'lr': 0.0013925819343709683, 'batch_size': 16}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:20:00,231] Trial 7 finished with value: 0.018207430839538574 and parameters: {'units': 42, 'layers': 2, 'dropout': 0.23750665564136014, 'lr': 0.0007513451060499139, 'batch_size': 8}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:20:07,038] Trial 8 finished with value: 0.0017176956171169877 and parameters: {'units': 70, 'layers': 2, 'dropout': 0.3377900520583421, 'lr': 0.007760365138437988, 'batch_size': 32}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:20:13,486] Trial 9 finished with value: 0.000456834037322551 and parameters: {'units': 94, 'layers': 2, 'dropout': 0.45999889043318853, 'lr': 0.005338887172697169, 'batch_size': 16}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:20:27,190] Trial 10 finished with value: 0.051665160804986954 and parameters: {'units': 128, 'layers': 1, 'dropout': 0.13509656168983997, 'lr': 0.0001444916570892813, 'batch_size': 32}. Best is trial 2 with value: 0.0003266715502832085.\n",
            "[I 2025-08-19 12:20:30,955] Trial 11 finished with value: 0.00031148866401053965 and parameters: {'units': 99, 'layers': 1, 'dropout': 0.4832778799847652, 'lr': 0.0032483705610681056, 'batch_size': 16}. Best is trial 11 with value: 0.00031148866401053965.\n",
            "[I 2025-08-19 12:20:37,169] Trial 12 finished with value: 7.024894148344174e-05 and parameters: {'units': 103, 'layers': 1, 'dropout': 0.3648153263573667, 'lr': 0.0027531239390954114, 'batch_size': 32}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:20:40,807] Trial 13 finished with value: 0.0002991274814121425 and parameters: {'units': 116, 'layers': 1, 'dropout': 0.41505730609652997, 'lr': 0.0028599805695145282, 'batch_size': 16}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:20:44,835] Trial 14 finished with value: 0.0012515565613284707 and parameters: {'units': 121, 'layers': 1, 'dropout': 0.3955821910204914, 'lr': 0.0022819850641448884, 'batch_size': 32}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:20:49,124] Trial 15 finished with value: 0.00042262981878593564 and parameters: {'units': 112, 'layers': 1, 'dropout': 0.42359817446334164, 'lr': 0.002788529387204676, 'batch_size': 16}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:20:52,531] Trial 16 finished with value: 0.004379400052130222 and parameters: {'units': 109, 'layers': 1, 'dropout': 0.35846262316058386, 'lr': 0.008275122950966877, 'batch_size': 32}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:20:57,541] Trial 17 finished with value: 0.058185286819934845 and parameters: {'units': 84, 'layers': 1, 'dropout': 0.27726997617818416, 'lr': 0.0005199193006387998, 'batch_size': 16}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:21:02,837] Trial 18 finished with value: 0.0003373754443600774 and parameters: {'units': 127, 'layers': 1, 'dropout': 0.4407658712842858, 'lr': 0.0020164796952626715, 'batch_size': 32}. Best is trial 12 with value: 7.024894148344174e-05.\n",
            "[I 2025-08-19 12:21:06,563] Trial 19 finished with value: 8.00013222033158e-05 and parameters: {'units': 108, 'layers': 1, 'dropout': 0.36694990421280854, 'lr': 0.004910265310470955, 'batch_size': 8}. Best is trial 12 with value: 7.024894148344174e-05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'units': 103, 'layers': 1, 'dropout': 0.3648153263573667, 'lr': 0.0027531239390954114, 'batch_size': 32}\n",
            "\n",
            "==============================\n",
            "Country: Iraq | Top partner: Italy (0.88)\n",
            "==============================\n",
            "Not enough data for Iraq. Skipping.\n",
            "\n",
            "==============================\n",
            "Country: Afghanistan | Top partner: India (0.51)\n",
            "==============================\n",
            "Too short sequence for Afghanistan. Skipping.\n",
            "\n",
            "===== GDP Impact Summary (2026, 40% drop in top partner's imports, Tuned LSTM) =====\n",
            "  country top_partner    baseline_gdp_2026       shock_gdp_2026  \\\n",
            "0  Canada         USA 2,179,241,254,901.17 2,184,160,342,480.90   \n",
            "\n",
            "           gdp_loss  gdp_loss_pct  \n",
            "0 -4,919,087,579.73         -0.23  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import optuna\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# load data & filter\n",
        "e = pd.read_csv(\"export_processed.csv\", encoding=\"latin1\")\n",
        "i = pd.read_csv(\"integrated_master.csv\", encoding=\"latin1\")\n",
        "cs = [\"India\",\"USA\",\"Russia\",\"France\",\"Germany\",\"Italy\",\"China\",\"Japan\",\"Argentina\",\"Portugal\",\"Spain\",\"Croatia\",\"Belgium\",\"Australia\",\"Pakistan\",\"Afghanistan\",\"Israel\",\"Iran\",\"Iraq\",\"Bangladesh\",\"Sri Lanka\",\"Canada\",\"UK\",\"Sweden\",\"Saudi Arabia\"]\n",
        "e = e[e[\"reporterDesc\"].isin(cs)]\n",
        "\n",
        "# vuln calc\n",
        "mx = e.groupby([\"reporterDesc\",\"refYear\"])[\"TradeDependencyIndex\"].max().reset_index()\n",
        "av = mx.groupby(\"reporterDesc\")[\"TradeDependencyIndex\"].mean().reset_index()\n",
        "t3 = av.sort_values(by=\"TradeDependencyIndex\", ascending=False).head(3)\n",
        "print(\"\\nTop 3 vulnerable (by avg yearly max TDI):\")\n",
        "print(t3)\n",
        "\n",
        "# partner pick\n",
        "tp = []\n",
        "for c in t3[\"reporterDesc\"]:\n",
        "    s = e[e[\"reporterDesc\"]==c]\n",
        "    yr = s[\"refYear\"].max()\n",
        "    sl = s[s[\"refYear\"]==yr]\n",
        "    p = sl.sort_values(\"TradeDependencyIndex\", ascending=False).iloc[0]\n",
        "    tp.append({\"c\":c,\"p\":p[\"partnerDesc\"],\"shr\":p[\"TradeDependencyIndex\"],\"y\":yr})\n",
        "\n",
        "tpd = pd.DataFrame(tp)\n",
        "print(\"\\nTop partner & export share (latest year):\")\n",
        "print(tpd)\n",
        "\n",
        "# seq maker\n",
        "def ms(X,y,w=3):\n",
        "    xx,yy = [],[]\n",
        "    for k in range(len(X)-w):\n",
        "        xx.append(X[k:k+w])\n",
        "        yy.append(y[k+w])\n",
        "    return np.array(xx),np.array(yy)\n",
        "\n",
        "# optuna obj\n",
        "def o(tr,Xtr,ytr,Xv,yv,inp):\n",
        "    u = tr.suggest_int(\"u\",32,128)\n",
        "    l = tr.suggest_int(\"l\",1,3)\n",
        "    d = tr.suggest_float(\"d\",0.1,0.5)\n",
        "    lr = tr.suggest_loguniform(\"lr\",1e-4,1e-2)\n",
        "    m = keras.Sequential()\n",
        "    for j in range(l):\n",
        "        rs = (j<l-1)\n",
        "        if j==0:\n",
        "            m.add(layers.LSTM(u,activation=\"tanh\",return_sequences=rs,input_shape=inp))\n",
        "        else:\n",
        "            m.add(layers.LSTM(u,activation=\"tanh\",return_sequences=rs))\n",
        "        m.add(layers.Dropout(d))\n",
        "    m.add(layers.Dense(1))\n",
        "    m.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),loss=\"mse\")\n",
        "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,restore_best_weights=True)\n",
        "    h = m.fit(Xtr,ytr,validation_data=(Xv,yv),epochs=100,batch_size=tr.suggest_categorical(\"bs\",[8,16,32]),verbose=0,callbacks=[es])\n",
        "    return min(h.history[\"val_loss\"])\n",
        "\n",
        "# run per country\n",
        "sm = []\n",
        "fs = [\"imports_goods_services_gdp_pct\",\"exports_goods_services_gdp_pct\",\"trade_gdp_pct\",\"inflation_consumer_prices_pct\",\"gdp_growth_pct\",\"trade_balance_gdp_pct\",\"gdp_growth_stability\",\"inflation_stability\",\"HHI_export\",\"Diversification_export\",\"HHI_import\",\"Diversification_import\",\"Trade_Diversification_Index\",\"Overall_Trade_Dependency\"]\n",
        "tg = \"gdp_current_usd\"\n",
        "\n",
        "for _,r in tpd.iterrows():\n",
        "    c = r[\"c\"]\n",
        "    p = r[\"p\"]\n",
        "    shr = r[\"shr\"]\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"Country: {c} | Top partner: {p} ({shr:.2f})\")\n",
        "    print(\"==============================\")\n",
        "    d = i[i[\"Country Name\"]==c].copy()\n",
        "    d = d.dropna(subset=fs+[tg])\n",
        "    if d.empty or d[\"Year\"].nunique()<10:\n",
        "        print(f\"Not enough data for {c}. Skipping.\")\n",
        "        continue\n",
        "    sx = MinMaxScaler()\n",
        "    sy = MinMaxScaler()\n",
        "    X = sx.fit_transform(d[fs])\n",
        "    y = sy.fit_transform(d[[tg]])\n",
        "    Xs,ys = ms(X,y,3)\n",
        "    if len(Xs)<10:\n",
        "        print(f\"Too short sequence for {c}. Skipping.\")\n",
        "        continue\n",
        "    yrs = d[\"Year\"].values[3:]\n",
        "    trc = np.where(yrs<=2022)[0][-1]\n",
        "    vc = np.where(yrs<=2024)[0][-1]\n",
        "    Xtr,Ytr = Xs[:trc+1],ys[:trc+1]\n",
        "    Xv,Yv = Xs[trc+1:vc+1],ys[trc+1:vc+1]\n",
        "    Xt,Yt = Xs[vc+1:],ys[vc+1:]\n",
        "    st = optuna.create_study(direction=\"minimize\")\n",
        "    st.optimize(lambda tr:o(tr,Xtr,Ytr,Xv,Yv,(Xtr.shape[1],Xtr.shape[2])),n_trials=20,timeout=300)\n",
        "    bp = st.best_params\n",
        "    print(\"Best params:\",bp)\n",
        "    bm = keras.Sequential()\n",
        "    for j in range(bp[\"l\"]):\n",
        "        rs = (j<bp[\"l\"]-1)\n",
        "        if j==0:\n",
        "            bm.add(layers.LSTM(bp[\"u\"],activation=\"tanh\",return_sequences=rs,input_shape=(Xtr.shape[1],Xtr.shape[2])))\n",
        "        else:\n",
        "            bm.add(layers.LSTM(bp[\"u\"],activation=\"tanh\",return_sequences=rs))\n",
        "        bm.add(layers.Dropout(bp[\"d\"]))\n",
        "    bm.add(layers.Dense(1))\n",
        "    bm.compile(optimizer=keras.optimizers.Adam(learning_rate=bp[\"lr\"]),loss=\"mse\")\n",
        "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,restore_best_weights=True)\n",
        "    bm.fit(np.concatenate([Xtr,Xv]),np.concatenate([Ytr,Yv]),epochs=200,batch_size=bp[\"bs\"],verbose=0,callbacks=[es])\n",
        "    ls = Xs[-1:]\n",
        "    bl = bm.predict(ls,verbose=0)[0][0]\n",
        "    blv = sy.inverse_transform([[bl]])[0,0]\n",
        "    sh = ls.copy()\n",
        "    idx = fs.index(\"Overall_Trade_Dependency\")\n",
        "    sh[0,-1,idx] *= (1-0.40*shr)\n",
        "    shv = bm.predict(sh,verbose=0)[0][0]\n",
        "    shv = sy.inverse_transform([[shv]])[0,0]\n",
        "    loss = blv-shv\n",
        "    lp = loss/blv*100\n",
        "    sm.append({\"c\":c,\"tp\":p,\"bl\":blv,\"sh\":shv,\"loss\":loss,\"lp\":lp})\n",
        "\n",
        "if sm:\n",
        "    s = pd.DataFrame(sm).sort_values(\"lp\",ascending=False)\n",
        "    pd.set_option(\"display.float_format\",lambda v:f\"{v:,.2f}\")\n",
        "    print(\"\\n===== GDP Impact Summary (2026, 40% drop in top partner's imports, Tuned LSTM) =====\")\n",
        "    print(s)\n",
        "else:\n",
        "    print(\"\\n No valid countries had enough data for tuned LSTM modeling.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjDVHPY-JBsW",
        "outputId": "a4d8ec7d-d66c-436d-e0b3-8083604540c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-19 12:50:34,709] A new study created in memory with name: no-name-d8de42bd-1209-49e7-a4b8-d813799df77c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using features (8): ['imports_goods_services_gdp_pct', 'exports_goods_services_gdp_pct', 'trade_gdp_pct', 'inflation_consumer_prices_pct', 'gdp_growth_pct', 'trade_balance_gdp_pct', 'gdp_growth_stability', 'inflation_stability']\n",
            "20 countries available for training.\n",
            "Starting Optuna tuning (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-19 12:50:44,171] Trial 0 finished with value: 0.001070842845365405 and parameters: {'seq_len': 6, 'units': 111, 'n_layers': 1, 'dropout': 0.23037268093189525, 'lr': 0.008704452829501101, 'batch_size': 64}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:51:11,919] Trial 1 finished with value: 0.0022032465785741806 and parameters: {'seq_len': 5, 'units': 87, 'n_layers': 2, 'dropout': 0.3886832540440106, 'lr': 0.0005266794604241971, 'batch_size': 32}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:51:19,634] Trial 2 finished with value: 0.006389304995536804 and parameters: {'seq_len': 7, 'units': 93, 'n_layers': 1, 'dropout': 0.04236702868169387, 'lr': 0.0008461530081708932, 'batch_size': 32}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:51:26,139] Trial 3 finished with value: 0.00955226644873619 and parameters: {'seq_len': 4, 'units': 60, 'n_layers': 1, 'dropout': 0.19972785876753668, 'lr': 0.0026523743541563183, 'batch_size': 64}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:51:38,824] Trial 4 finished with value: 0.00772259384393692 and parameters: {'seq_len': 7, 'units': 68, 'n_layers': 1, 'dropout': 0.30364133223663053, 'lr': 0.000313153944134123, 'batch_size': 32}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:52:02,568] Trial 5 finished with value: 0.0033378456719219685 and parameters: {'seq_len': 6, 'units': 73, 'n_layers': 2, 'dropout': 0.105048298262993, 'lr': 0.0003129555219019622, 'batch_size': 32}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:52:27,615] Trial 6 finished with value: 0.0017919223755598068 and parameters: {'seq_len': 4, 'units': 71, 'n_layers': 2, 'dropout': 0.1795502412576013, 'lr': 0.0007779910688982894, 'batch_size': 32}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:52:32,629] Trial 7 finished with value: 0.011740591377019882 and parameters: {'seq_len': 3, 'units': 65, 'n_layers': 1, 'dropout': 0.16574920418826006, 'lr': 0.0015633484437379138, 'batch_size': 32}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:52:53,145] Trial 8 finished with value: 0.004348021000623703 and parameters: {'seq_len': 3, 'units': 101, 'n_layers': 1, 'dropout': 0.10368873024170724, 'lr': 0.001676368903413798, 'batch_size': 16}. Best is trial 0 with value: 0.001070842845365405.\n",
            "[I 2025-08-19 12:53:06,606] Trial 9 finished with value: 0.0007371063693426549 and parameters: {'seq_len': 7, 'units': 116, 'n_layers': 1, 'dropout': 0.241765763359599, 'lr': 0.003208166830949583, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:53:31,695] Trial 10 finished with value: 0.00951475091278553 and parameters: {'seq_len': 6, 'units': 120, 'n_layers': 2, 'dropout': 0.2912192992360619, 'lr': 0.00010686019922967302, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:53:37,827] Trial 11 finished with value: 0.008317935280501842 and parameters: {'seq_len': 6, 'units': 128, 'n_layers': 1, 'dropout': 0.2670032955337455, 'lr': 0.00954044963331935, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:53:44,708] Trial 12 finished with value: 0.005708747543394566 and parameters: {'seq_len': 7, 'units': 110, 'n_layers': 1, 'dropout': 0.24137660814541054, 'lr': 0.007975354000924978, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:53:56,247] Trial 13 finished with value: 0.0008606014889664948 and parameters: {'seq_len': 6, 'units': 35, 'n_layers': 1, 'dropout': 0.3415172669989631, 'lr': 0.004303362782489414, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:54:09,698] Trial 14 finished with value: 0.0009615354938432574 and parameters: {'seq_len': 5, 'units': 35, 'n_layers': 1, 'dropout': 0.3701886294371039, 'lr': 0.003878005094511436, 'batch_size': 16}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:54:14,713] Trial 15 finished with value: 0.007022998295724392 and parameters: {'seq_len': 7, 'units': 41, 'n_layers': 1, 'dropout': 0.3421735160294909, 'lr': 0.003996840650954061, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:54:24,744] Trial 16 finished with value: 0.000958787917625159 and parameters: {'seq_len': 5, 'units': 51, 'n_layers': 1, 'dropout': 0.30483926872994593, 'lr': 0.004331819250356151, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:54:39,607] Trial 17 finished with value: 0.0012855699751526117 and parameters: {'seq_len': 6, 'units': 81, 'n_layers': 2, 'dropout': 0.3389604850547635, 'lr': 0.00201647260904323, 'batch_size': 64}. Best is trial 9 with value: 0.0007371063693426549.\n",
            "[I 2025-08-19 12:54:53,180] Trial 18 finished with value: 0.0006485609337687492 and parameters: {'seq_len': 7, 'units': 44, 'n_layers': 1, 'dropout': 0.24159158618946538, 'lr': 0.005061541402477744, 'batch_size': 16}. Best is trial 18 with value: 0.0006485609337687492.\n",
            "[I 2025-08-19 12:55:04,062] Trial 19 finished with value: 0.001073445426300168 and parameters: {'seq_len': 7, 'units': 50, 'n_layers': 1, 'dropout': 0.1197155258916017, 'lr': 0.00557569351074499, 'batch_size': 16}. Best is trial 18 with value: 0.0006485609337687492.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial params:\n",
            "{'seq_len': 7, 'units': 44, 'n_layers': 1, 'dropout': 0.24159158618946538, 'lr': 0.005061541402477744, 'batch_size': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x784ff6663880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1: max incremental GDP% = 2.078412\n",
            "Round 2: max incremental GDP% = 2.808705\n",
            "Round 3: max incremental GDP% = 4.013193\n",
            "Round 4: max incremental GDP% = 5.933151\n",
            "Round 5: max incremental GDP% = 8.945497\n",
            "Round 6: max incremental GDP% = 13.969789\n",
            "Round 7: max incremental GDP% = 22.047909\n",
            "Round 8: max incremental GDP% = 34.621623\n",
            "Round 9: max incremental GDP% = 54.165284\n",
            "Round 10: max incremental GDP% = 84.512063\n",
            "Round 11: max incremental GDP% = 131.599276\n",
            "Round 12: max incremental GDP% = 204.622538\n",
            "Round 13: max incremental GDP% = 317.822966\n",
            "Round 14: max incremental GDP% = 493.254607\n",
            "Round 15: max incremental GDP% = 765.069692\n",
            "Round 16: max incremental GDP% = 1186.154168\n",
            "Round 17: max incremental GDP% = 1838.402462\n",
            "Round 18: max incremental GDP% = 2848.627423\n",
            "Round 19: max incremental GDP% = 4413.195979\n",
            "Round 20: max incremental GDP% = 6836.176045\n",
            "\n",
            "=== Top 5 countries by GDP % loss after China 25% export shock and propagation ===\n",
            "    country  gdp_loss_pct     gdp_loss_abs_usd  export_share_to_china  \\\n",
            "0  Portugal    19265.5021  94354264932565.9688                 0.0117   \n",
            "1   Belgium    17051.2347 144164364103823.7500                 0.0272   \n",
            "2      Iraq    15675.5297  77032080595018.7656                 0.0414   \n",
            "3     Spain    14836.5110 198976979274372.3125                 0.0307   \n",
            "4    Sweden    13595.4896  82207020839901.5000                 0.0764   \n",
            "\n",
            "   cumulative_export_pctpts_loss  \n",
            "0                      7523.8442  \n",
            "1                      8030.7135  \n",
            "2                      7117.3903  \n",
            "3                      5232.6668  \n",
            "4                      5438.8090  \n"
          ]
        }
      ]
    }
  ]
}